{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Names of all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['Min','Max','Mean','Std','Median','Activity','Mobility','Complexity','Kurtosis','2nd Difference Mean','2nd Difference Max','Coeffiecient of Variation','Skewness','1st Difference Mean','1st Difference Max',\n",
    "          'Wavelet Approximate Mean','Wavelet Approximate Std Deviation','Wavelet Detailed Mean','Wavelet Detailed Std Deviation','Wavelet Approximate Energy','Wavelet Detailed Energy',\n",
    "          'Wavelet Approximate Entropy','Wavelet Detailed Entropy','Mean','Variance of Vertex to Vertex Slope','Mean','Variance of Vertex to Vertex Amplitude', 'Mean','Variance of Vertex to Vertex Time','FFT Delta MaxPower','FFT Theta MaxPower','FFT Alpha MaxPower','FFT Beta MaxPower',\n",
    "          'Shanon Entropy','Autro Regressive Mode Order 3 Coefficients for each channel ->']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean, Median, Std, Min and Max #New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_val(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        output[k] = np.mean(i) #saving the means\n",
    "        k=k+1\n",
    "    return np.sum(output)/k\n",
    "\n",
    "def std_val(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        output[k] = np.std(i) #saving the means\n",
    "        k=k+1\n",
    "    return np.sum(output)/k\n",
    "\n",
    "def max_val(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        if np.max(i)>0:\n",
    "            output[k] = np.max(i)#saving the means\n",
    "        else:\n",
    "            output[k] = 0#saving the means\n",
    "        k=k+1\n",
    "    return np.sum(output)/k\n",
    "\n",
    "def min_val(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        if np.min(i)<0:\n",
    "            output[k] = np.min(i)#saving the means\n",
    "        else:\n",
    "            output[k] = 0#saving the means\n",
    "        k=k+1\n",
    "    return np.sum(output)/k\n",
    "\n",
    "def median_val(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        output[k] = np.median(i)#saving the medians\n",
    "        k=k+1\n",
    "    return np.sum(output)/k\n",
    "\n",
    "def wrapper4(a):\n",
    "    mean_a =  mean_val(a)\n",
    "    std_a = std_val(a)\n",
    "    max_a  = max_val(a)\n",
    "    min_a = min_val(a)\n",
    "    median_a =  median_val(a)\n",
    "    return min_a,max_a,mean_a,std_a,median_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hjorth Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hjorth(input):                                             # function for hjorth \n",
    "    realinput = input\n",
    "    hjorth_activity = np.zeros(len(realinput))\n",
    "    hjorth_mobility = np.zeros(len(realinput))\n",
    "    hjorth_diffmobility = np.zeros(len(realinput))\n",
    "    hjorth_complexity = np.zeros(len(realinput))\n",
    "    k = 0\n",
    "    for l in realinput:\n",
    "        j = l[~np.isnan(l)]\n",
    "        diff_input = np.diff(j)\n",
    "        diff_diffinput = np.diff(diff_input)\n",
    "        hjorth_activity[k] = np.var(j)\n",
    "        hjorth_mobility[k] = np.sqrt(np.var(diff_input)/hjorth_activity[k])\n",
    "        hjorth_diffmobility[k] = np.sqrt(np.var(diff_diffinput)/np.var(diff_input))\n",
    "        hjorth_complexity[k] = hjorth_diffmobility[k]/hjorth_mobility[k]\n",
    "        k = k+1\n",
    "    return np.sum(hjorth_activity)/k, np.sum(hjorth_mobility)/k, np.sum(hjorth_complexity)/k                      #returning hjorth activity, hjorth mobility , hjorth complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis , 2nd Diff Mean, 2nd Diff Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_kurtosis(a):\n",
    "    b = a # Extracting the data from the 60 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 60)\n",
    "    k = 0; # For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        mean_i = np.mean(i) # Saving the mean of array i\n",
    "        std_i = np.std(i) # Saving the standard deviation of array i\n",
    "        t = 0.0\n",
    "        for j in i:\n",
    "            t += (pow((j-mean_i)/std_i,4)-3)\n",
    "        kurtosis_i = t/len(i) # Formula: (1/N)*(summation(x_i-mean)/standard_deviation)^4-3\n",
    "        output[k] = kurtosis_i # Saving the kurtosis in the array created\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/k\n",
    "\n",
    "##----------------------------------------- End Kurtosis Function ----------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMean(Absolute difference) Function ------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] --------------- ##\n",
    "##-------------------  -- [ Output: 1D array (2ndDiffMean values for each channel)] ----------##\n",
    "\n",
    "def secDiffMean(a):\n",
    "    b = a # Extracting the data of the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    for l in b:\n",
    "    \tt = 0.0\n",
    "        i = l[~np.isnan(l)]\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        for j in range(len(i)-2):\n",
    "            t += abs(temp1[j+1]-temp1[j]) # Summing the 2nd Diffs\n",
    "        output[k] = t/(len(i)-2) # Calculating the mean of the 2nd Diffs\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/k\n",
    "\n",
    "##------------------------------------- End 2ndDiffMean Function----- -------------------------##\n",
    "\n",
    "\n",
    "##------------------------------------- Begin 2ndDiffMax Function(Absolute difference) --------##\n",
    "##-------------------------- [ Input: 2D array (row: Channels, column: Data)] -----------------##\n",
    "##--------------------- [ Output: 1D array (2ndDiffMax values for each channel)] --------------##\n",
    "\n",
    "def secDiffMax(a):\n",
    "    b = a # Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) # Initializing the output array with zeros (length = 14)\n",
    "    temp1 = np.zeros(len(b[0])-1) # To store the 1st Diffs\n",
    "    k = 0; # For counting the current row no.\n",
    "    t = 0.0\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        for j in range(len(i)-1):\n",
    "            temp1[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "        t = temp1[1] - temp1[0]\n",
    "        for j in range(len(i)-2):\n",
    "            if abs(temp1[j+1]-temp1[j]) > t :\n",
    "            \tt = temp1[j+1]-temp1[j] # Comparing current Diff with the last updated Diff Max\n",
    "\n",
    "        output[k] = t # Storing the 2nd Diff Max for channel k\n",
    "        k +=1 # Updating the current row no.\n",
    "    return np.sum(output)/k\n",
    "\n",
    "\n",
    "\n",
    "def wrapper1(a):\n",
    "    kurtosis =  my_kurtosis(a)\n",
    "    sec_diff_mean = secDiffMean(a)\n",
    "    sec_diff_max  = secDiffMax(a)\n",
    "    return kurtosis,sec_diff_mean,sec_diff_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coefficient of Variaition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def coeff_var(a):\n",
    "    b = a #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    k = 0; #For counting the current row no.\n",
    "    for l in b:\n",
    "        i = l[~np.isnan(l)]\n",
    "        mean_i = np.mean(i) #Saving the mean of array i\n",
    "        std_i = np.std(i) #Saving the standard deviation of array i\n",
    "        output[k] = std_i/mean_i #computing coefficient of variation\n",
    "        k=k+1\n",
    "    return np.sum(output)/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Skewness , 1st Difference Mean, 1st Difference Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skewness(arr):\n",
    "    data = arr \n",
    "    skew_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for l in data:\n",
    "        i = l[~np.isnan(l)]\n",
    "        skew_array[index]=sp.stats.skew(i,axis=0,bias=True)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(skew_array)/index\n",
    "\n",
    "\n",
    "def first_diff_mean(arr):\n",
    "    data = arr \n",
    "    diff_mean_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for l in data:\n",
    "        i = l[~np.isnan(l)]\n",
    "        sum=0.0#initializing the sum at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            sum += abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "           \n",
    "        diff_mean_array[index]=sum/(len(i)-1)\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_mean_array)/index\n",
    "\n",
    "\n",
    "def first_diff_max(arr):\n",
    "    data = arr \n",
    "    diff_max_array = np.zeros(len(data)) #Initialinling the array as all 0s\n",
    "    first_diff = np.zeros(len(data[0])-1)#Initialinling the array as all 0s \n",
    "    index = 0; #current cell position in the output array\n",
    "   \n",
    "    for l in data:\n",
    "        i = l[~np.isnan(l)]\n",
    "        max=0.0#initializing at the start of each iteration\n",
    "        for j in range(len(i)-1):\n",
    "            first_diff[j] = abs(i[j+1]-i[j]) # Obtaining the 1st Diffs\n",
    "            if first_diff[j]>max: \n",
    "                max=first_diff[j] # finding the maximum of the first differences\n",
    "        diff_max_array[index]=max\n",
    "        index+=1 #updating the cell position\n",
    "    return np.sum(diff_max_array)/index\n",
    "\n",
    "\n",
    "def wrapper2(arr):\n",
    "    skew   = skewness(arr)\n",
    "    fdmean = first_diff_mean(arr)\n",
    "    fdmax  = first_diff_max(arr)\n",
    "    return skew,fdmean,fdmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_features(epoch):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    for i in range(60):\n",
    "        l=epoch[i,:]\n",
    "        j = l[~np.isnan(l)]\n",
    "        cA,cD=pywt.dwt(j,'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    for x in range(60):   \n",
    "        cA_mean.append(np.mean(cA_values[x]))\n",
    "        cA_std.append(np.std(cA_values[x]))\n",
    "        cA_Energy.append(np.sum(np.square(cA_values[x])))\n",
    "        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n",
    "        cD_std.append(np.std(cD_values[x]))\n",
    "        cD_Energy.append(np.sum(np.square(cD_values[x])))\n",
    "        Entropy_D.append(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x]))))\n",
    "        Entropy_A.append(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))\n",
    "    return np.sum(cA_mean)/60,np.sum(cA_std)/60,np.sum(cD_mean)/60,np.sum(cD_std)/60,np.sum(cA_Energy)/60,np.sum(cD_Energy)/60,np.sum(Entropy_A)/60,np.sum(Entropy_D)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Mean of Vertex to Vertex Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "from scipy.signal import argrelextrema\n",
    "\n",
    "def first_diff(i):\n",
    "    b=i\n",
    "    \n",
    "    \n",
    "    out = np.zeros(len(b))\n",
    "    \n",
    "    for j in range(len(i)):\n",
    "        out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "        j=j+1\n",
    "        c=out[1:len(out)]\n",
    "    return c\n",
    "\n",
    "#first_diff(s)\n",
    "\n",
    "def slope_mean(p):\n",
    "    b = p #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for m in b:\n",
    "        i = m\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]\n",
    "        t_max = argrelextrema(x, np.greater)[0]\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]\n",
    "        t_min = argrelextrema(x, np.less)[0]\n",
    "        t = np.concatenate((t_max,t_min),axis=0)\n",
    "        t.sort()#sort on the basis of time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q]         \n",
    "        output[k] = np.mean(res) \n",
    "        k=k+1\n",
    "    return np.sum(output)/k\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def first_diff(i):\n",
    "#     b=i\n",
    "    \n",
    "    \n",
    "#     out = np.zeros(len(b))\n",
    "    \n",
    "#     for j in range(len(i)):\n",
    "#         out[j] = b[j-1]-b[j]# Obtaining the 1st Diffs\n",
    "        \n",
    "#         j=j+1\n",
    "#         c=out[1:len(out)]\n",
    "#     return c #returns first diff\n",
    "\n",
    "\n",
    "def slope_var(p):\n",
    "    b = p #Extracting the data from the 14 channels\n",
    "    output = np.zeros(len(b)) #Initializing the output array with zeros\n",
    "    res = np.zeros(len(b)-1)\n",
    "    \n",
    "    k = 0; #For counting the current row no.\n",
    "    for m in b:\n",
    "        i = m\n",
    "        x=i\n",
    "        amp_max = i[argrelextrema(x, np.greater)[0]]#storing maxima value\n",
    "        t_max = argrelextrema(x, np.greater)[0]#storing time for maxima\n",
    "        amp_min = i[argrelextrema(x, np.less)[0]]#storing minima value\n",
    "        t_min = argrelextrema(x, np.less)[0]#storing time for minima value\n",
    "        t = np.concatenate((t_max,t_min),axis=0) #making a single matrix of all matrix\n",
    "        t.sort() #sorting according to time\n",
    "\n",
    "        h=0\n",
    "        amp = np.zeros(len(t))\n",
    "        res = np.zeros(len(t)-1)\n",
    "        for l in range(len(t)):\n",
    "            amp[l]=i[t[l]]\n",
    "           \n",
    "        \n",
    "        amp_diff = first_diff(amp)\n",
    "        \n",
    "        t_diff = first_diff(t)\n",
    "        \n",
    "        for q in range(len(amp_diff)):\n",
    "            res[q] = amp_diff[q]/t_diff[q] #calculating slope        \n",
    "    \n",
    "        output[k] = np.var(res) \n",
    "        k=k+1#counting k\n",
    "    return np.sum(output)/k\n",
    "\n",
    "def wrapper3(epoch):\n",
    "    var1 = slope_mean(epoch)\n",
    "    var2 = slope_var(epoch)\n",
    "    return var1,var2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance and Mean of Vertex to Vertex Ampltude and Time #New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import argrelextrema\n",
    "def v2v_amp_time(a):\n",
    "    b=a\n",
    "    vertex_time=[]\n",
    "    vertex_amplitude=[]\n",
    "    for i in b:\n",
    "        vertex_time.append((argrelextrema(i, np.greater))[0])\n",
    "        vertex_amplitude.append(i[argrelextrema(i, np.greater)[0]])\n",
    "    vertex_time_difference=[]\n",
    "    vertex_amplitude_difference=[]\n",
    "    variance_amplitude=[]\n",
    "    mean_amplitude=[]\n",
    "    mean_time=[]\n",
    "    variance_time=[]\n",
    "    n = len(b)\n",
    "    for i in range(n):\n",
    "        vertex_time_difference.append(abs(np.diff(vertex_time[i])))\n",
    "        vertex_amplitude_difference.append(abs(np.diff(vertex_amplitude[i])))\n",
    "    for i in range(n):\n",
    "        mean_amplitude.append(np.mean(vertex_amplitude_difference[i]))\n",
    "        variance_amplitude.append(np.var(vertex_amplitude_difference[i]))\n",
    "        mean_time.append(np.mean(vertex_time_difference[i]))\n",
    "        variance_time.append(np.var(vertex_time_difference[i]))\n",
    "        \n",
    "    return np.mean(mean_amplitude) , np.mean(variance_amplitude) , np.mean(mean_time) , np.mean(variance_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFT features(Max Power) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def maxPwelch(data_win,Fs):\n",
    " \n",
    "    \n",
    "    BandF = [0.1, 3, 7, 12, 30]\n",
    "    PMax = np.zeros([60,(len(BandF)-1)]);\n",
    "    \n",
    "    for j in range(60):\n",
    "        l=data_win[j,:]\n",
    "        k = l[~np.isnan(l)]\n",
    "        f,Psd = signal.welch(k, Fs)\n",
    "        \n",
    "        for i in range(len(BandF)-1):\n",
    "            fr = np.where((f>BandF[i]) & (f<=BandF[i+1]))\n",
    "            PMax[j,i] = np.max(Psd[fr])\n",
    "    \n",
    "    return np.sum(PMax[:,0])/60,np.sum(PMax[:,1])/60,np.sum(PMax[:,2])/60,np.sum(PMax[:,3])/60\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shanon Entropy and Entropy Spectral [Not Used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entropy(b): # Shanon Entropy\n",
    "    \"\"\" Computes entropy of 0-1 vector. \"\"\"\n",
    "    entropy_list = []\n",
    "    for labels in b:\n",
    "        labels = labels[~np.isnan(labels)]\n",
    "        labels = np.array([0 if x<0 else x for x in labels])\n",
    "        n_labels = len(labels)\n",
    "        counts = np.bincount(labels.astype(int))\n",
    "        probs = counts[np.nonzero(counts)].astype(float) / n_labels\n",
    "        n_classes = len(probs)\n",
    "\n",
    "        if n_classes <= 1:\n",
    "            entropy_list.append(0)\n",
    "        entropy_list.append(- np.sum(probs * np.log(probs)) / np.log(n_classes))\n",
    "    return np.mean(entropy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoregressive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model- Yule Walker Algorithm [Not Used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParameters(labels):\n",
    "    b_labels = len(labels)\n",
    "    feature = []\n",
    "    for i in labels:\n",
    "        k = i[~np.isnan(l)]\n",
    "        coeff, sig = alg.AR_est_YW(k, 11,)\n",
    "        feature.append(coeff)\n",
    "    a = []     \n",
    "    for i in range(11):\n",
    "        a.append(np.sum(feature[:][i])/60)\n",
    "     \n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoregression model- Burg Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParametersBurg(labels):\n",
    "    feature = []\n",
    "    feature1 = []\n",
    "    model_order = 3\n",
    "    for i in range(60):\n",
    "        l = labels[i]\n",
    "        k = l[~np.isnan(l)]\n",
    "        AR, rho, ref = arburg(k, model_order)\n",
    "        feature.append(AR);\n",
    "    for j in range(60):\n",
    "        for i in range(model_order):\n",
    "            feature1.append(feature[j][i])\n",
    "\n",
    "    return feature1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached loop no 1 out of 240 (0.416667 Percent)\n",
      "Reached loop no 2 out of 240 (0.833333 Percent)\n",
      "Reached loop no 3 out of 240 (1.250000 Percent)\n",
      "Reached loop no 4 out of 240 (1.666667 Percent)\n",
      "Reached loop no 5 out of 240 (2.083333 Percent)\n",
      "Reached loop no 6 out of 240 (2.500000 Percent)\n",
      "Reached loop no 7 out of 240 (2.916667 Percent)\n",
      "Reached loop no 8 out of 240 (3.333333 Percent)\n",
      "Reached loop no 9 out of 240 (3.750000 Percent)\n",
      "Reached loop no 10 out of 240 (4.166667 Percent)\n",
      "Reached loop no 11 out of 240 (4.583333 Percent)\n",
      "Reached loop no 12 out of 240 (5.000000 Percent)\n",
      "Reached loop no 13 out of 240 (5.416667 Percent)\n",
      "Reached loop no 14 out of 240 (5.833333 Percent)\n",
      "Reached loop no 15 out of 240 (6.250000 Percent)\n",
      "Reached loop no 16 out of 240 (6.666667 Percent)\n",
      "Reached loop no 17 out of 240 (7.083333 Percent)\n",
      "Reached loop no 18 out of 240 (7.500000 Percent)\n",
      "Reached loop no 19 out of 240 (7.916667 Percent)\n",
      "Reached loop no 20 out of 240 (8.333333 Percent)\n",
      "Reached loop no 21 out of 240 (8.750000 Percent)\n",
      "Reached loop no 22 out of 240 (9.166667 Percent)\n",
      "Reached loop no 23 out of 240 (9.583333 Percent)\n",
      "Reached loop no 24 out of 240 (10.000000 Percent)\n",
      "Reached loop no 25 out of 240 (10.416667 Percent)\n",
      "Reached loop no 26 out of 240 (10.833333 Percent)\n",
      "Reached loop no 27 out of 240 (11.250000 Percent)\n",
      "Reached loop no 28 out of 240 (11.666667 Percent)\n",
      "Reached loop no 29 out of 240 (12.083333 Percent)\n",
      "Reached loop no 30 out of 240 (12.500000 Percent)\n",
      "Reached loop no 31 out of 240 (12.916667 Percent)\n",
      "Reached loop no 32 out of 240 (13.333333 Percent)\n",
      "Reached loop no 33 out of 240 (13.750000 Percent)\n",
      "Reached loop no 34 out of 240 (14.166667 Percent)\n",
      "Reached loop no 35 out of 240 (14.583333 Percent)\n",
      "Reached loop no 36 out of 240 (15.000000 Percent)\n",
      "Reached loop no 37 out of 240 (15.416667 Percent)\n",
      "Reached loop no 38 out of 240 (15.833333 Percent)\n",
      "Reached loop no 39 out of 240 (16.250000 Percent)\n",
      "Reached loop no 40 out of 240 (16.666667 Percent)\n",
      "Reached loop no 41 out of 240 (17.083333 Percent)\n",
      "Reached loop no 42 out of 240 (17.500000 Percent)\n",
      "Reached loop no 43 out of 240 (17.916667 Percent)\n",
      "Reached loop no 44 out of 240 (18.333333 Percent)\n",
      "Reached loop no 45 out of 240 (18.750000 Percent)\n",
      "Reached loop no 46 out of 240 (19.166667 Percent)\n"
     ]
    }
   ],
   "source": [
    "data = csv.reader(open('l1b_mat/l1b.csv')) #data\n",
    "labels = csv.reader(open('l1b_mat/labels.csv')) #labels of the data\n",
    "begining = csv.reader(open('l1b_mat/begining.csv')) #Starting points for each trial\n",
    "\n",
    "csvfile = \"Features_New/l1b_features.csv\"\n",
    "\n",
    "read_file = open(csvfile, \"a\")\n",
    "\n",
    "with read_file as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(names) \n",
    "    y = np.empty((0,1),str)\n",
    "    X_start = np.empty((0,1),int)\n",
    "    for l in labels:\n",
    "        y = np.append(y, np.array([l]), axis=0)\n",
    "    for l in begining:\n",
    "        X_start = np.append(X_start, np.array([l]), axis=0)\n",
    "    X_start = X_start.astype(float)\n",
    "    X_start = X_start.astype(int)\n",
    "    X_start = np.transpose(X_start)\n",
    "    t=0\n",
    "    count=0\n",
    "\n",
    "    for i in X_start[0]:\n",
    "        print('Reached loop no %d out of %d (%f Percent)'%((t+1),len(y),(float(t+1)*100/len(y))))\n",
    "        X = np.empty((0,60), float)\n",
    "        while(count<i-1):\n",
    "            data.next()\n",
    "            count = count+1\n",
    "        while(count<i-1+2560):\n",
    "            X = np.append(X, np.array([data.next()]), axis=0)\n",
    "            count = count+1\n",
    "        features = []\n",
    "        X = np.transpose(X)\n",
    "        X = X.astype(float)\n",
    "        epoch = X # 256Hz signal, epoch contains signal for 10 seconds\n",
    "        if len(epoch[0]) == 0:\n",
    "            break\n",
    "\n",
    "        # Min, Max, Mean, Standard Deviation, Median\n",
    "        feature_list = wrapper4(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "        \n",
    "            \n",
    "        # Hjorth Parameters\n",
    "        feature_list = hjorth(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "\n",
    "        #Kurtosis , 2nd Diff Mean, 2nd Diff Max\n",
    "        feature_list = wrapper1(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "\n",
    "        #Coeffeicient of Variation\n",
    "        feat = coeff_var(epoch)\n",
    "        features.append(feat)\n",
    "\n",
    "        #Skewness , 1st Difference Mean, 1st Difference Max\n",
    "        feature_list = wrapper2(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "\n",
    "\n",
    "        # wavelet transform features \n",
    "        feature_list = wavelet_features(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "\n",
    "\n",
    "        # Variance and mean of Vertex to Vertex Slope\n",
    "        feature_list = wrapper3(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "            \n",
    "        # Variance and mean of Vertex to Vertex Amplitude and Time\n",
    "        feature_list = v2v_amp_time(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "\n",
    "\n",
    "        #Fast Fourier Transform features(Max Power) ***\n",
    "        feature_list  =  maxPwelch(epoch,256)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat)\n",
    "            \n",
    "        # Shanon Entropy\n",
    "        features.append(entropy(epoch))\n",
    "\n",
    "        #Autoregressive model Coefficients ***\n",
    "        feature_list = autogressiveModelParametersBurg(epoch)\n",
    "        for feat in feature_list:\n",
    "            features.append(feat.real)\n",
    "\n",
    "        features.append(y[t][0]);\n",
    "        t = t+1\n",
    "\n",
    "        writer.writerow(features)\n",
    "read_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024897484505827183"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization( Wait till the csv file gets populated then run the code below after the features are extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = csv.reader(open('Features_New/l1b_features.csv')) # Here your csv file\n",
    "lines = [l for l in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(lines[1])-1):  \n",
    "    columns = []\n",
    "    for j in range(1,len(lines)):\n",
    "        columns.append(float(lines[j][i]))\n",
    "    mean = np.mean(columns,axis = 0)\n",
    "    std_dev  = np.std(columns,axis = 0)\n",
    "    \n",
    "    for j in range(1,len(lines)):\n",
    "        lines[j][i] = (float(lines[j][i])-mean)/std_dev\n",
    "fo = open('Features_New/l1b_Normalizedfeatures.csv', 'wb')\n",
    "writer = csv.writer(fo) # This file will store the normalized features\n",
    "writer.writerows(lines)\n",
    "fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
